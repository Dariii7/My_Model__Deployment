{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bee1b4a",
   "metadata": {},
   "source": [
    "# Preparing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449cfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the tools we need\n",
    "\n",
    "# Regular EDA (exploratory data analysis) and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# we want our plots to appear inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# Models from Scikit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Model Evaluations\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486bbd06",
   "metadata": {},
   "source": [
    "# Data Exploring "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eaa806d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760665ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba892e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many positive (1) and negative (0) samples we have in our dataframe\n",
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94923a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the value counts with a bar graph\n",
    "df.target.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dd0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd17669",
   "metadata": {},
   "source": [
    "# Heart Disease Frequency According to Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e250f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3ae39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare target column with sex column\n",
    "pd.crosstab(df.target, df.sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f2a26",
   "metadata": {},
   "source": [
    "# Making our crosstab visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca81b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plot\n",
    "pd.crosstab(df.target, df.sex).plot(kind=\"bar\", figsize=(10,6), color=[\"salmon\", \"lightblue\"])\n",
    "\n",
    "# Add some attributes to it\n",
    "plt.title(\"Heart Disease Frequency for Sex\")\n",
    "plt.xlabel(\"0 = No Disease, 1 = Disease\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.legend([\"Female\", \"Male\"])\n",
    "plt.xticks(rotation=0); # keep the labels on the x-axis vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff6ebf",
   "metadata": {},
   "source": [
    "# Age vs Max Heart rate for Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another figure\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Start with positve examples\n",
    "plt.scatter(df.age[df.target==1],df.thalach[df.target==1],c=\"salmon\") # define it as a scatter figure\n",
    "\n",
    "# Now for negative examples, we want them on the same plot, so we call plt again\n",
    "plt.scatter(df.age[df.target==0], \n",
    "            df.thalach[df.target==0], \n",
    "            c=\"lightblue\") # axis always come as (x, y)\n",
    "\n",
    "# Add some helpful info\n",
    "plt.title(\"Heart Disease in function of Age and Max Heart Rate\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.legend([\"Disease\", \"No Disease\"])\n",
    "plt.ylabel(\"Max Heart Rate\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms are a great way to check the distribution of a variable\n",
    "df.age.plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3760a242",
   "metadata": {},
   "source": [
    "# Heart Disease Frequency per Chest Pain Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424dee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.cp, df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f871386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new crosstab and base plot\n",
    "pd.crosstab(df.cp, df.target).plot(kind=\"bar\", \n",
    "                                   figsize=(10,6), \n",
    "                                   color=[\"lightblue\", \"salmon\"])\n",
    "\n",
    "# Add attributes to the plot to make it more readable\n",
    "plt.title(\"Heart Disease Frequency Per Chest Pain Type\")\n",
    "plt.xlabel(\"Chest Pain Type\")\n",
    "plt.ylabel(\"Amount\")\n",
    "plt.legend([\"No Disease\", \"Disease\"])\n",
    "plt.xticks(rotation = 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a7c64",
   "metadata": {},
   "source": [
    "# Correlation between independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation between our independent variables\n",
    "corr_matrix = df.corr()\n",
    "corr_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d523905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make it look a little prettier\n",
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True, \n",
    "            linewidths=0.5, \n",
    "            fmt= \".2f\", \n",
    "            cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39467ca6",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25bf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d142c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything except target variable\n",
    "X = df.drop(\"target\", axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972c649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (no target column)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551228da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6c1b01",
   "metadata": {},
   "source": [
    "# Training and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split into train & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, # independent variables \n",
    "                                                    y, # dependent variable\n",
    "                                                    test_size = 0.2) # percentage of data to use for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c350216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699cdf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e7fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9e6a1",
   "metadata": {},
   "source": [
    "# Model Choices"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d61e1dad",
   "metadata": {},
   "source": [
    "Now we've got our data prepared, we can start to fit models. We'll be using the following and comparing their results.\n",
    "\n",
    "Logistic Regression - LogisticRegression()\n",
    "K-Nearest Neighbors - KNeighboursClassifier()\n",
    "RandomForest - RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568edd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in a dictionary\n",
    "models = {\"KNN\": KNeighborsClassifier(),\n",
    "          \"Logistic Regression\": LogisticRegression(), \n",
    "          \"Random Forest\": RandomForestClassifier()}\n",
    "\n",
    "# Create function to fit and score models\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluates given machine learning models.\n",
    "    models : a dict of different Scikit-Learn machine learning models\n",
    "    X_train : training data\n",
    "    X_test : testing data\n",
    "    y_train : labels assosciated with training data\n",
    "    y_test : labels assosciated with test data\n",
    "    \"\"\"\n",
    "    # Random seed for reproducible results\n",
    "    np.random.seed(42)\n",
    "    # Make a list to keep model scores\n",
    "    model_scores = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        # Fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # Evaluate the model and append its score to model_scores\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores = fit_and_score(models=models,\n",
    "                             X_train=X_train,\n",
    "                             X_test=X_test,\n",
    "                             y_train=y_train,\n",
    "                             y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94e973",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare = pd.DataFrame(model_scores, index=['accuracy'])\n",
    "model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9a179",
   "metadata": {},
   "source": [
    "# Tune KNeighborsClassifier (K-Nearest Neighbors or KNN) by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc12a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of train scores\n",
    "train_scores = []\n",
    "\n",
    "# Create a list of test scores\n",
    "test_scores = []\n",
    "\n",
    "# Create a list of different values for n_neighbors\n",
    "neighbors = range(1, 21) # 1 to 20\n",
    "\n",
    "# Setup algorithm\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Loop through different neighbors values\n",
    "for i in neighbors:\n",
    "    knn.set_params(n_neighbors = i) # set neighbors value\n",
    "    \n",
    "    # Fit the algorithm\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Update the training scores\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    \n",
    "    # Update the test scores\n",
    "    test_scores.append(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e74be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neighbors, train_scores, label=\"Train score\")\n",
    "plt.plot(neighbors, test_scores, label=\"Test score\")\n",
    "plt.xticks(np.arange(1, 21, 1))\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Model score\")\n",
    "plt.legend()\n",
    "\n",
    "print(f\"Maximum KNN score on the test data: {max(test_scores)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d761f3",
   "metadata": {},
   "source": [
    "# Tuning models with with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b0f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different LogisticRegression hyperparameters\n",
    "log_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n",
    "                \"solver\": [\"liblinear\"]}\n",
    "\n",
    "# Different RandomForestClassifier hyperparameters\n",
    "rf_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n",
    "           \"max_depth\": [None, 3, 5, 10],\n",
    "           \"min_samples_split\": np.arange(2, 20, 2),\n",
    "           \"min_samples_leaf\": np.arange(1, 20, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93da63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for LogisticRegression\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n",
    "                                param_distributions=log_reg_grid,\n",
    "                                cv=5,\n",
    "                                n_iter=20,\n",
    "                                verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search model\n",
    "rs_log_reg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d49797",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7efd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbfd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup random hyperparameter search for RandomForestClassifier\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                           param_distributions=rf_grid,\n",
    "                           cv=5,\n",
    "                           n_iter=20,\n",
    "                           verbose=True)\n",
    "\n",
    "# Fit random hyperparameter search model\n",
    "rs_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameters\n",
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the randomized search random forest model\n",
    "rs_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ced2c",
   "metadata": {},
   "source": [
    "# Evaluating a classification model, beyond accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cbc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make preidctions on test data\n",
    "y_preds = rs_log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad76611",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c41e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50934f1e",
   "metadata": {},
   "source": [
    "# ROC Curve and AUC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ROC curve function from metrics module\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "# Plot ROC curve and calculate AUC metric\n",
    "plot_roc_curve(rs_log_reg, X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b909a8",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78682828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "print(confusion_matrix(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ee329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Seaborn\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5) # Increase font size\n",
    "\n",
    "def plot_conf_mat(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    Plots a confusion matrix using Seaborn's heatmap().\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    ax = sns.heatmap(confusion_matrix(y_test, y_preds),\n",
    "                     annot=True, # Annotate the boxes\n",
    "                     cbar=False)\n",
    "    plt.xlabel(\"true label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "    \n",
    "plot_conf_mat(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba58b3a",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15ed203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show classification report\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331275e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check best hyperparameters\n",
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Instantiate best model with best hyperparameters (found with GridSearchCV)\n",
    "clf = LogisticRegression(C=0.23357214690901212,\n",
    "                         solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac75cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated accuracy score\n",
    "cv_acc = cross_val_score(clf,\n",
    "                         X,\n",
    "                         y,\n",
    "                         cv=5, # 5-fold cross-validation\n",
    "                         scoring=\"accuracy\") # accuracy as scoring\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_acc = np.mean(cv_acc)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0423ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated precision score\n",
    "cv_precision = np.mean(cross_val_score(clf,\n",
    "                                       X,\n",
    "                                       y,\n",
    "                                       cv=5, # 5-fold cross-validation\n",
    "                                       scoring=\"precision\")) # precision as scoring\n",
    "cv_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc37f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated recall score\n",
    "cv_recall = np.mean(cross_val_score(clf,\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    cv=5, # 5-fold cross-validation\n",
    "                                    scoring=\"recall\")) # recall as scoring\n",
    "cv_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated F1 score\n",
    "cv_f1 = np.mean(cross_val_score(clf,\n",
    "                                X,\n",
    "                                y,\n",
    "                                cv=5, # 5-fold cross-validation\n",
    "                                scoring=\"f1\")) # f1 as scoring\n",
    "cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing cross-validated metrics\n",
    "cv_metrics = pd.DataFrame({\"Accuracy\": cv_acc,\n",
    "                            \"Precision\": cv_precision,\n",
    "                            \"Recall\": cv_recall,\n",
    "                            \"F1\": cv_f1},\n",
    "                          index=[0])\n",
    "cv_metrics.T.plot.bar(title=\"Cross-Validated Metrics\", legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7778e2e3",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an instance of LogisticRegression (taken from above)\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b14ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check coef_\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0051a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match features to columns\n",
    "features_dict = dict(zip(df.columns, list(clf.coef_[0])))\n",
    "features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909a229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "features_df = pd.DataFrame(features_dict, index=[0])\n",
    "features_df.T.plot.bar(title=\"Feature Importance\", legend=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80498763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df[\"sex\"], df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast slope (positive coefficient) with target\n",
    "pd.crosstab(df[\"slope\"], df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc45617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091702a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
